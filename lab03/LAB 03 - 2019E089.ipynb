{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a694b3dd",
   "metadata": {},
   "source": [
    "# Q1)  Study the dataset ’Fashion-MNIST’ in Keras. Answer the following questions in relation to the above dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f375b2",
   "metadata": {},
   "source": [
    "a)  Find out whether it can be used for regression or classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08dc23",
   "metadata": {},
   "source": [
    " Ans) It is used for classification tasks rather than regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a2a458",
   "metadata": {},
   "source": [
    "b) What is the size of the images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eebec72",
   "metadata": {},
   "source": [
    "Ans) 28x28 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aff431",
   "metadata": {},
   "source": [
    "c)  How many images are there in the train data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2fdef8",
   "metadata": {},
   "source": [
    "Ans) Total of 60,000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67796c",
   "metadata": {},
   "source": [
    "d)  State the number of images in test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bafaff2",
   "metadata": {},
   "source": [
    "Ans) Total of 10,000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e73e98",
   "metadata": {},
   "source": [
    "e) How many classes are there in the data? Write down those classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf541166",
   "metadata": {},
   "source": [
    "Ans) There are 10 classes in the Fashion-MNIST dataset.\n",
    "1. T-shirt/top\n",
    "2. Trouser\n",
    "3. Pullover\n",
    "4. Dress\n",
    "5. Coat\n",
    "6. Sandal\n",
    "7. Shirt\n",
    "8. Sneaker\n",
    "9. Bag\n",
    "10. Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe3b0e",
   "metadata": {},
   "source": [
    "# Q2)  Load that dataset directly from Keras using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8177b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 14us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 42s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 4s 1us/step\n",
      "Shape of train_images: (60000, 28, 28)\n",
      "Shape of train_labels: (60000,)\n",
      "Shape of test_images: (10000, 28, 28)\n",
      "Shape of test_labels: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Load the Fashion-MNIST dataset\n",
    "(tr_im, tr_la), (te_im, te_la) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(\"Shape of train_images:\", tr_im.shape)\n",
    "print(\"Shape of train_labels:\", tr_la.shape)\n",
    "print(\"Shape of test_images:\", te_im.shape)\n",
    "print(\"Shape of test_labels:\", te_la.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e23ab8",
   "metadata": {},
   "source": [
    "# Q3) View some images in training data, for example draw the 11th image in your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f525f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "\n",
    "\n",
    "# Display the 11th image\n",
    "pp.imshow(tr_im[10], cmap='gray')\n",
    "pp.axis('off')\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0792d51",
   "metadata": {},
   "source": [
    "# Q4) Normalize your data (train and test) between 0 and 1. Hint: This is a grayscale image has pixel values between 0 and 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce493ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values of the training and test images\n",
    "tr_im = tr_im / 255.0\n",
    "te_im = te_im / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61087c08",
   "metadata": {},
   "source": [
    "# Q5)  Now divide the training data into two: Validation images (first 5000 images from the initial training data) and Training images (rest of the images in your initial training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737eddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the training data into validation and training sets\n",
    "val_im = tr_im[:5000]\n",
    "val_la = tr_la[:5000]\n",
    "train_im = tr_im[5000:]\n",
    "train_la = tr_la[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52540e9e",
   "metadata": {},
   "source": [
    "# Q6) Initialize the weight and bias parameters of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e862ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Initialize the weight parameters\n",
    "weight_ini = tf.keras.initializers.GlorotUniform()\n",
    "weights = weight_ini(shape=(2, 2))\n",
    "\n",
    "# Initialize the bias parameters\n",
    "bias_ini = tf.keras.initializers.Zeros()\n",
    "biases = bias_ini(shape=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7723d5",
   "metadata": {},
   "source": [
    "# Q7)  Now build the neural network model with the following characteristics,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24a70e",
   "metadata": {},
   "source": [
    "a) One Flatten layer as the input layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d981d90",
   "metadata": {},
   "source": [
    "b) Two dense relu layers as hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eac11b",
   "metadata": {},
   "source": [
    "c) A dense softmax layer as the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade6d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "n_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten layer as the input layer\n",
    "    tf.keras.layers.Dense(256, activation='relu'),  # First dense relu layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Second dense relu layer\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # Dense softmax layer as the output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f591666",
   "metadata": {},
   "source": [
    "# Q8) Answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f295be0",
   "metadata": {},
   "source": [
    "a) What is the use of Flatten layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f2a0a3",
   "metadata": {},
   "source": [
    "Ans) The Flatten layer is used to convert multidimensional input data into a one-dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1590a0",
   "metadata": {},
   "source": [
    "b)  Generally, softmax activation function is used in the output layer of the classification networks. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef63d3c",
   "metadata": {},
   "source": [
    "Ans) Because it produces a probability distribution over multiple classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0a2e8",
   "metadata": {},
   "source": [
    "# Q9) Print the summary of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0158d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "n_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eeb8fc",
   "metadata": {},
   "source": [
    "# Q10) Now compile the model with the desired loss function, optimizer and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8927e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "n_model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb78cd4",
   "metadata": {},
   "source": [
    "# Q11) Now train your model on the training data and validate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1a9b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 20s 9ms/step - loss: 0.4753 - accuracy: 0.8293 - val_loss: 0.3515 - val_accuracy: 0.8740\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.3568 - accuracy: 0.8691 - val_loss: 0.3168 - val_accuracy: 0.8872\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3232 - accuracy: 0.8806 - val_loss: 0.2863 - val_accuracy: 0.8934\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3002 - accuracy: 0.8873 - val_loss: 0.2732 - val_accuracy: 0.8982\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2818 - accuracy: 0.8943 - val_loss: 0.2614 - val_accuracy: 0.9024\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2688 - accuracy: 0.9000 - val_loss: 0.2509 - val_accuracy: 0.9060\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2549 - accuracy: 0.9030 - val_loss: 0.2379 - val_accuracy: 0.9108\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2442 - accuracy: 0.9075 - val_loss: 0.2120 - val_accuracy: 0.9210\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2362 - accuracy: 0.9102 - val_loss: 0.2252 - val_accuracy: 0.9160\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2248 - accuracy: 0.9153 - val_loss: 0.2008 - val_accuracy: 0.9254\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = n_model.fit(tr_im, tr_la, validation_data=(val_im, val_la),\n",
    "                    epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e29d2",
   "metadata": {},
   "source": [
    "# Q12) Evaluate your model on the test data. What is the accuracy of your model on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ddebecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 971us/step - loss: 0.3377 - accuracy: 0.8874\n",
      "Accuracy on test data: 88.74%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = n_model.evaluate(te_im, te_la)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy on test data: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42dc8a9",
   "metadata": {},
   "source": [
    "# Q13) Now take the first five samples of test data. Print the actual target classes and the predicted target classes of those five samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a12a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 188ms/step\n",
      "Actual target classes:\n",
      "[9 2 1 1 6]\n",
      "\n",
      "Predicted target classes:\n",
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Predict target classes for the first five samples\n",
    "pred = n_model.predict(te_im[:5])\n",
    "\n",
    "# Convert predicted probabilities to target classes\n",
    "pred_cl = tf.argmax(pred, axis=1).numpy()\n",
    "\n",
    "# Print actual and predicted target classes\n",
    "print(\"Actual target classes:\")\n",
    "print(te_la[:5])\n",
    "print(\"\\nPredicted target classes:\")\n",
    "print(pred_cl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
